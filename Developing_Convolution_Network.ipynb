{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushanttwayana/ML-DL-Strategies-Toolkit/blob/main/Developing_Convolution_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1f2a462a-15b6-4bb3-bd13-0af3689b2f9b",
      "metadata": {
        "id": "1f2a462a-15b6-4bb3-bd13-0af3689b2f9b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the convolution operation\n",
        "def convolve(image, filt):\n",
        "    # Get the dimensions of the image and filter\n",
        "    image_height, image_width = image.shape\n",
        "    filt_height, filt_width = filt.shape\n",
        "\n",
        "    # Calculate the output dimensions\n",
        "    output_height = image_height - filt_height + 1\n",
        "    output_width = image_width - filt_width + 1\n",
        "\n",
        "    # Initialize the output\n",
        "    output = np.zeros((output_height, output_width))\n",
        "\n",
        "    # Perform the convolution operation\n",
        "    for i in range(output_height):\n",
        "        for j in range(output_width):\n",
        "            output[i, j] = np.sum(image[i:i+filt_height, j:j+filt_width] * filt)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bc4c6e10-45df-4b0f-94f8-05b4d8e38331",
      "metadata": {
        "id": "bc4c6e10-45df-4b0f-94f8-05b4d8e38331"
      },
      "outputs": [],
      "source": [
        "# Define the max pooling operation\n",
        "def max_pooling(image, size=2):\n",
        "    # Get the dimensions of the image\n",
        "    height, width = image.shape\n",
        "\n",
        "    # Calculate the output dimensions\n",
        "    output_height = height // size\n",
        "    output_width = width // size\n",
        "\n",
        "    # Initialize the output\n",
        "    output = np.zeros((output_height, output_width))\n",
        "\n",
        "    # Perform max pooling\n",
        "    for i in range(0, height-size+1, size):\n",
        "        for j in range(0, width-size+1, size):\n",
        "            output[i//size, j//size] = np.max(image[i:i+size, j:j+size])\n",
        "\n",
        "    return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4143d6c5-a01f-463f-a5e5-925624331298",
      "metadata": {
        "id": "4143d6c5-a01f-463f-a5e5-925624331298"
      },
      "outputs": [],
      "source": [
        "# Initialize a sample image (5x5)\n",
        "sample_image = np.random.rand(5, 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b1d7b8c2-8e89-4ef5-b64b-45bcce699aa0",
      "metadata": {
        "id": "b1d7b8c2-8e89-4ef5-b64b-45bcce699aa0"
      },
      "outputs": [],
      "source": [
        "# Initialize a sample filter (3x3)\n",
        "sample_filter = np.random.rand(3, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6bd0927e-1242-4da5-a0ba-4f607d42ec60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bd0927e-1242-4da5-a0ba-4f607d42ec60",
        "outputId": "25a68f52-66ed-4bdc-f6c8-462e4de5ed8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convolution Result:\n",
            "[[2.8515453  3.40680761 2.99305499]\n",
            " [2.26716968 2.58903427 2.372304  ]\n",
            " [1.30382508 2.01550156 2.12915101]]\n"
          ]
        }
      ],
      "source": [
        "# Perform convolution\n",
        "conv_result = convolve(sample_image, sample_filter)\n",
        "print(\"Convolution Result:\")\n",
        "print(conv_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9047c865-43b8-4af9-96ab-881516028390",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9047c865-43b8-4af9-96ab-881516028390",
        "outputId": "ff48e849-fe4a-4800-f094-f782317c39df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Max Pooling Result:\n",
            "[[3.40680761]]\n"
          ]
        }
      ],
      "source": [
        "# Perform max pooling\n",
        "pool_result = max_pooling(conv_result)\n",
        "print(\"\\nMax Pooling Result:\")\n",
        "print(pool_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5434b60d-68e1-471a-9b77-a75381c26d72",
      "metadata": {
        "id": "5434b60d-68e1-471a-9b77-a75381c26d72"
      },
      "outputs": [],
      "source": [
        "##now adding training Part\n",
        "class SimpleCNN:\n",
        "    def __init__(self):\n",
        "        # Initialize the weights randomly for a single convolutional layer\n",
        "        self.conv_filter = np.random.randn(3, 3)  # Example filter of size 3x3\n",
        "\n",
        "    def forward(self, image):\n",
        "        # Forward pass through the convolutional layer and max pooling\n",
        "        conv_result = convolve(image, self.conv_filter)\n",
        "        pooled_result = max_pooling(conv_result)\n",
        "        return pooled_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e47823c7-2578-4b9a-8008-6db1482acb85",
      "metadata": {
        "id": "e47823c7-2578-4b9a-8008-6db1482acb85"
      },
      "outputs": [],
      "source": [
        "# Training setup\n",
        "# Generate random training data and labels (for demonstration purposes)\n",
        "train_data = np.random.rand(10, 5, 5)  # 10 images of size 5x5\n",
        "train_labels = np.random.randint(0, 2, size=10)  # Random labels (binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c9f94fda-7a19-44aa-aaa3-9346899c2915",
      "metadata": {
        "id": "c9f94fda-7a19-44aa-aaa3-9346899c2915"
      },
      "outputs": [],
      "source": [
        "# Initialize the CNN model\n",
        "model = SimpleCNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cd5b061a-5e51-4a82-8ef2-a2c67362c6bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd5b061a-5e51-4a82-8ef2-a2c67362c6bd",
        "outputId": "a30d7d00-ca16-4972-9606-43f78a19415d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Average Loss: 1.7347\n",
            "Epoch [2/10], Average Loss: 1.7347\n",
            "Epoch [3/10], Average Loss: 1.7347\n",
            "Epoch [4/10], Average Loss: 1.7347\n",
            "Epoch [5/10], Average Loss: 1.7347\n",
            "Epoch [6/10], Average Loss: 1.7347\n",
            "Epoch [7/10], Average Loss: 1.7347\n",
            "Epoch [8/10], Average Loss: 1.7347\n",
            "Epoch [9/10], Average Loss: 1.7347\n",
            "Epoch [10/10], Average Loss: 1.7347\n"
          ]
        }
      ],
      "source": [
        "# Training loop (forward propagation only for simplicity)\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, image in enumerate(train_data):\n",
        "        # Forward pass\n",
        "        prediction = model.forward(image)\n",
        "\n",
        "        # For simplicity, calculate a dummy loss\n",
        "        loss = np.square(prediction - train_labels[i]).sum()\n",
        "\n",
        "        # Accumulate total loss for monitoring\n",
        "        total_loss += loss\n",
        "\n",
        "        # Backpropagation and weight updates are not included in this simplified example\n",
        "\n",
        "    # Calculate average loss per epoch\n",
        "    avg_loss = total_loss / len(train_data)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Note: In a real training loop, you would also need to implement backward propagation,\n",
        "# weight updates using gradients, a loss function like Cross Entropy, and an optimizer like SGD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ce2e99d3-111b-414c-b490-32510ef09eda",
      "metadata": {
        "id": "ce2e99d3-111b-414c-b490-32510ef09eda"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN:\n",
        "    def __init__(self):\n",
        "        # Initialize the weights randomly for a single convolutional layer\n",
        "        self.conv_filter = np.random.randn(3, 3)  # Example filter of size 3x3\n",
        "\n",
        "    def forward(self, image):\n",
        "        # Forward pass through the convolutional layer and max pooling\n",
        "        conv_result = convolve(image, self.conv_filter)\n",
        "        pooled_result = max_pooling(conv_result)\n",
        "        return pooled_result\n",
        "\n",
        "    def backward(self, image, prediction, label, learning_rate=0.001):\n",
        "        # Calculate loss (MSE - Mean Squared Error)\n",
        "        loss = np.square(prediction - label).sum()\n",
        "\n",
        "        # Calculate gradients\n",
        "        d_loss = 2 * (prediction - label)  # Derivative of MSE loss\n",
        "        d_pooled = np.zeros_like(prediction)  # Derivative w.r.t. pooled_result\n",
        "\n",
        "        # Backpropagation through max pooling (in this simple example, gradient flows unchanged)\n",
        "        for i in range(prediction.shape[0]):\n",
        "            for j in range(prediction.shape[1]):\n",
        "                d_pooled[i, j] = d_loss[i, j]\n",
        "\n",
        "        # Calculate the gradient with respect to the filter weights\n",
        "        d_filter = np.zeros_like(self.conv_filter)\n",
        "        for i in range(image.shape[0] - d_pooled.shape[0] + 1):\n",
        "            for j in range(image.shape[1] - d_pooled.shape[1] + 1):\n",
        "                d_filter += image[i:i + d_pooled.shape[0], j:j + d_pooled.shape[1]] * d_pooled\n",
        "\n",
        "        # Update filter weights using gradient descent\n",
        "        self.conv_filter -= learning_rate * d_filter\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "068ab312-0a54-44ed-b77a-a3e1161969c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "068ab312-0a54-44ed-b77a-a3e1161969c1",
        "outputId": "aad9204d-e4a1-47e2-94f2-5cde94629926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Average Loss: 2.2673\n",
            "Epoch [2/10], Average Loss: 0.7125\n",
            "Epoch [3/10], Average Loss: 0.5450\n",
            "Epoch [4/10], Average Loss: 0.5175\n",
            "Epoch [5/10], Average Loss: 0.5114\n",
            "Epoch [6/10], Average Loss: 0.5098\n",
            "Epoch [7/10], Average Loss: 0.5094\n",
            "Epoch [8/10], Average Loss: 0.5093\n",
            "Epoch [9/10], Average Loss: 0.5093\n",
            "Epoch [10/10], Average Loss: 0.5093\n"
          ]
        }
      ],
      "source": [
        "# Training setup\n",
        "# Generate random training data and labels (for demonstration purposes)\n",
        "train_data = np.random.rand(10, 5, 5)  # 10 images of size 5x5\n",
        "train_labels = np.random.rand(10, 2)  # Random labels (example with 2 classes)\n",
        "\n",
        "# Initialize the CNN model\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Training loop (forward, backward propagation, and weight updates)\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, image in enumerate(train_data):\n",
        "        # Forward pass\n",
        "        prediction = model.forward(image)\n",
        "\n",
        "        # Backward pass (calculate gradients and update weights)\n",
        "        loss = model.backward(image, prediction, train_labels[i], learning_rate=learning_rate)\n",
        "\n",
        "        # Accumulate total loss for monitoring\n",
        "        total_loss += loss\n",
        "\n",
        "    # Calculate average loss per epoch\n",
        "    avg_loss = total_loss / len(train_data)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "005dcdfc-ed5c-42ad-b674-2e8eb3353c72",
      "metadata": {
        "id": "005dcdfc-ed5c-42ad-b674-2e8eb3353c72"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49dd5046-8f81-4fdb-aa70-fd30dc4d6b58",
      "metadata": {
        "id": "49dd5046-8f81-4fdb-aa70-fd30dc4d6b58"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7033df86-3245-4af5-a587-ff029fd551b6",
      "metadata": {
        "id": "7033df86-3245-4af5-a587-ff029fd551b6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcfde7c7-b8c6-4218-aac3-45681124ce01",
      "metadata": {
        "id": "bcfde7c7-b8c6-4218-aac3-45681124ce01"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60a712a2-9892-45a3-bdea-31ad81aa60bb",
      "metadata": {
        "id": "60a712a2-9892-45a3-bdea-31ad81aa60bb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54e01b5d-7f23-4105-881f-12c30b6d7f91",
      "metadata": {
        "id": "54e01b5d-7f23-4105-881f-12c30b6d7f91"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}